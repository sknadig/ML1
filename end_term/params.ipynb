{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import math\n",
    "from sklearn import datasets, base\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from copy import deepcopy\n",
    "import itertools\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(n_jobs = -1),\n",
    "    SVC(probability = True),\n",
    "#     GaussianProcessClassifier(n_jobs = -1),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier()]\n",
    "\n",
    "# classifiers_name = [\"KNN\", \"SVM\", \"GP\", \"DT\", \"RF\"]\n",
    "classifiers_name = [\"KNN\", \"SVM\", \"DT\", \"RF\"]\n",
    "beta = \"XGB\"\n",
    "\n",
    "parameters = {\"KNN\":{\"n_neighbors\":[]},\n",
    "              \"SVM\":{\"C\":[],\"kernel\":[],\"degree\":[]},\n",
    "              \"GP\":{\"kernel\":[],\"n_restarts_optimizer\":[]},\n",
    "              \"DT\":{\"splitter\":[], \"max_depth\":[]},\n",
    "              \"RF\":{\"n_estimators\":[], \"max_depth\":[] },\n",
    "              \"XGB\":{\"learning_rate\":[], \"n_estimators\":[], \"max_depth\":[],\"min_child_weight\":[]}\n",
    "            }\n",
    "classifier_parameters = []\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "Df = pd.DataFrame()\n",
    "Df[\"X\"] = X.tolist()\n",
    "Df[\"Y\"] = Y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sample_hp_Ai(Ai):\n",
    "    global classifier_parameters\n",
    "    if(Ai is \"KNN\"):\n",
    "        parameters[\"KNN\"][\"n_neighbors\"] = math.ceil(np.random.uniform(100))\n",
    "        classifier_parameters.append(parameters[\"KNN\"].copy())\n",
    "        return(parameters[\"KNN\"])\n",
    "    elif(Ai is \"SVM\"):\n",
    "        parameters[\"SVM\"][\"C\"] = float(\"{0:.2f}\".format(abs(np.random.normal(loc=1.0, scale=1.0))))\n",
    "        parameters[\"SVM\"][\"kernel\"] = str(np.random.choice([\"linear\", \"rbf\"]))\n",
    "        parameters[\"SVM\"][\"degree\"] = np.random.randint(1,4)\n",
    "        classifier_parameters.append(parameters[\"SVM\"].copy())\n",
    "        return(parameters[\"SVM\"])\n",
    "    elif(Ai is \"GP\"):\n",
    "        parameters[\"GP\"][\"kernel\"] = str(np.random.choice([\"linear\", \"rbf\"]))\n",
    "        parameters[\"GP\"][\"n_restarts_optimizer\"] = np.random.randint(1,10)\n",
    "        classifier_parameters.append(parameters[\"GP\"].copy())\n",
    "        return(parameters[\"GP\"])\n",
    "    elif(Ai is \"DT\"):\n",
    "        parameters[\"DT\"][\"splitter\"] = np.random.choice([\"best\", \"random\"])\n",
    "        parameters[\"DT\"][\"max_depth\"] = np.random.randint(1,100)\n",
    "        classifier_parameters.append(parameters[\"DT\"].copy())\n",
    "        return(parameters[\"DT\"])\n",
    "    elif(Ai is \"RF\"):\n",
    "        parameters[\"RF\"][\"n_estimators\"] = np.random.randint(1,20)\n",
    "        parameters[\"RF\"][\"max_depth\"] = np.random.randint(1,100)\n",
    "        classifier_parameters.append(parameters[\"RF\"].copy())\n",
    "        return(parameters[\"RF\"])\n",
    "    elif(Ai is \"XGB\"):\n",
    "        parameters[\"XGB\"][\"learning_rate\"].append(float(\"{0:.2f}\".format(abs(np.random.normal(loc=1.0, scale=1.0)))))\n",
    "        parameters[\"XGB\"][\"n_estimators\"].append(np.random.randint(800,2000))\n",
    "        parameters[\"XGB\"][\"max_depth\"].append(np.random.randint(5,200))\n",
    "        parameters[\"XGB\"][\"min_child_weight\"].append(np.random.randint(1,10))\n",
    "        classifier_parameters.append(parameters[\"XGB\"].copy())\n",
    "        return(parameters[\"XGB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_params(A, B, P, N):\n",
    "    mu = np.random.dirichlet(P)\n",
    "    N = [int(mu_i*N) for mu_i in mu]\n",
    "    [sample_hp_Ai(classifiers_name[i]) for i in range(len(classifiers_name)) for j in range(N[i])]\n",
    "    Phi = sample_hp_Ai(\"XGB\")\n",
    "    Psi = [parameters[key] for key in parameters if key is not \"XGB\"]\n",
    "    return Phi, N, Psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Phi, N, Psi = get_params(classifiers_name, \"RF\", P=(np.arange(1,len(classifiers_name)+1)*100)[::-1], N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Blend:\n",
    "    def __init__(self, A = [\"KNN\", \"SVM\", \"GP\", \"DT\", \"RF\"], B = \"XGB\",D = [], L = 2, Phi = [], Psi = [], N=100 ):\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.D = D\n",
    "        self.L = L\n",
    "        self.Phi = Phi\n",
    "        self.Psi = Psi\n",
    "        self.N = N\n",
    "                    \n",
    "    def fit(self, A, B, D, L, Phi, N, Psi):\n",
    "#         p = np.random.normal(loc=0.7, scale=0.1)\n",
    "        p=0.7\n",
    "        D_fw = pd.DataFrame()\n",
    "        M = []\n",
    "        F = []\n",
    "        G = []\n",
    "        for l in range(1,L+1):\n",
    "            D_dash = D.sample(frac=p)\n",
    "            orig_index = sorted(Df.index.tolist())\n",
    "            train_index = sorted(D_dash.index.tolist())\n",
    "            test_index = sorted(set(orig_index) - set(train_index))\n",
    "            D_dash_bar = Df.ix[test_index]\n",
    "            classifier_index = 0\n",
    "            for i in range(0,len(classifiers_name)):\n",
    "                temp = []\n",
    "                if(N[i]):\n",
    "                    for j in range(0,N[i]):\n",
    "                        temp_clf = None\n",
    "                        temp_clf = classifiers[i].set_params(**classifier_parameters[classifier_index])\n",
    "                        temp_clf = temp_clf.fit(X = D_dash[\"X\"].tolist(), y = D_dash[\"Y\"].tolist())\n",
    "                        temp.append(deepcopy(temp_clf))\n",
    "                        classifier_index += 1\n",
    "                M.append(temp)\n",
    "            for row in D_dash_bar[\"X\"]:\n",
    "                F_temp = []\n",
    "                G_temp = []\n",
    "                for models in M:\n",
    "                    for model in models:\n",
    "                        M_bc = model.predict_proba([row])\n",
    "                        F_temp += [xa*ele for xa in row for ele in M_bc[0]]\n",
    "                        G_temp += [ele for ele in M_bc[0]]\n",
    "                F.append(F_temp)\n",
    "                G.append(G_temp)\n",
    "            d_assign = [list(itertools.chain.from_iterable(ele)) for ele in \\\n",
    "                        list(zip(D_dash_bar[\"X\"].tolist().copy(),F.copy(),G.copy()))]\n",
    "            D_fw[\"X\"] = d_assign\n",
    "            D_fw[\"Y\"] = D_dash_bar[\"Y\"].tolist().copy()\n",
    "            D_fw = D_fw.reset_index()\n",
    "            \n",
    "            Beta = xgb.XGBClassifier()\n",
    "            Beta.set_params(**classifier_parameters[-1])\n",
    "#             Beta = Beta.fit(X=D_fw[\"X\"], y=D_fw[\"Y\"])\n",
    "        return(M,D_dash,F,G, D_fw, Beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def blending_ensemble(A, B, D, P, N, k, R):\n",
    "    L = 2\n",
    "    M = []\n",
    "    for r in range(1,R+1):\n",
    "        Phi_r, N_r, Psi_r = get_params(A, B, P, N=10)\n",
    "        eps_r = cross_val_score(Blend(), A, B, D, L, Phi, Psi, N, cv=k)\n",
    "        print(eps_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b =Blend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "M_temp, D_dash, F, G, D_fw, Beta = b.fit(A=classifiers_name, B=\"XGB\", D=Df, L=1, Phi=Phi, N=N, Psi=Psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=[0.02], max_delta_step=0, max_depth=[149],\n",
       "       min_child_weight=[8], missing=None, n_estimators=[967], nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Beta = xgb.XGBClassifier()\n",
    "Beta.set_params(**classifier_parameters[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = D_fw[\"X\"]\n",
    "YY = D_fw[\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3197f3f9c48a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mBeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0mevals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_features_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "Beta.fit(XX,YY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS = SVC(**classifier_parameters[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-b6a2e8c0fc72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                       force_all_finite)\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "SS.fit(XX,YY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
