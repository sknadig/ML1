{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import math\n",
    "from sklearn import datasets, base\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from copy import deepcopy\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(n_jobs = -1),\n",
    "    SVC(probability = True),\n",
    "    GaussianProcessClassifier(n_jobs = -1),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier()]\n",
    "\n",
    "# classifiers_name = [\"KNN\", \"SVM\", \"GP\", \"DT\", \"RF\"]\n",
    "classifiers_name = [\"KNN\"]\n",
    "beta = \"XGB\"\n",
    "\n",
    "parameters = {\"KNN\":{\"n_neighbors\":[]},\n",
    "              \"SVM\":{\"C\":[],\"kernel\":[],\"degree\":[]},\n",
    "              \"GP\":{\"kernel\":[],\"n_restarts_optimizer\":[]},\n",
    "              \"DT\":{\"splitter\":[], \"max_depth\":[]},\n",
    "              \"RF\":{\"n_estimators\":[], \"max_depth\":[] },\n",
    "              \"XGB\":{\"learning_rate\":[], \"n_estimators\":[], \"max_depth\":[],\"min_child_weight\":[]}\n",
    "            }\n",
    "classifier_parameters = []\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "Df = pd.DataFrame()\n",
    "Df[\"X\"] = X.tolist()\n",
    "Df[\"Y\"] = Y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sample_hp_Ai(Ai):\n",
    "    global classifier_parameters\n",
    "    if(Ai is \"KNN\"):\n",
    "        parameters[\"KNN\"][\"n_neighbors\"] = math.ceil(np.random.uniform(100))\n",
    "        classifier_parameters.append(parameters[\"KNN\"].copy())\n",
    "        return(parameters[\"KNN\"])\n",
    "    elif(Ai is \"SVM\"):\n",
    "        parameters[\"SVM\"][\"C\"] = float(\"{0:.2f}\".format(abs(np.random.normal(loc=1.0, scale=1.0))))\n",
    "        parameters[\"SVM\"][\"kernel\"] = str(np.random.choice([\"linear\", \"rbf\"]))\n",
    "        parameters[\"SVM\"][\"degree\"] = np.random.randint(1,4)\n",
    "        classifier_parameters.append(parameters[\"SVM\"].copy())\n",
    "        return(parameters[\"SVM\"])\n",
    "    elif(Ai is \"GP\"):\n",
    "        parameters[\"GP\"][\"kernel\"] = str(np.random.choice([\"linear\", \"rbf\"]))\n",
    "        parameters[\"GP\"][\"n_restarts_optimizer\"] = np.random.randint(1,10)\n",
    "        classifier_parameters.append(parameters[\"GP\"].copy())\n",
    "        return(parameters[\"GP\"])\n",
    "    elif(Ai is \"DT\"):\n",
    "        parameters[\"DT\"][\"splitter\"] = np.random.choice([\"best\", \"random\"])\n",
    "        parameters[\"DT\"][\"max_depth\"] = np.random.randint(1,100)\n",
    "        classifier_parameters.append(parameters[\"DT\"].copy())\n",
    "        return(parameters[\"DT\"])\n",
    "    elif(Ai is \"RF\"):\n",
    "        parameters[\"RF\"][\"n_estimators\"] = np.random.randint(1,20)\n",
    "        parameters[\"RF\"][\"max_depth\"] = np.random.randint(1,100)\n",
    "        classifier_parameters.append(parameters[\"RF\"].copy())\n",
    "        return(parameters[\"RF\"])\n",
    "    elif(Ai is \"XGB\"):\n",
    "        parameters[\"XGB\"][\"learning_rate\"].append(float(\"{0:.2f}\".format(abs(np.random.normal(loc=1.0, scale=1.0)))))\n",
    "        parameters[\"XGB\"][\"n_estimators\"].append(np.random.randint(800,2000))\n",
    "        parameters[\"XGB\"][\"max_depth\"].append(np.random.randint(5,200))\n",
    "        parameters[\"XGB\"][\"min_child_weight\"].append(np.random.randint(1,10))\n",
    "        classifier_parameters.append(parameters[\"XGB\"].copy())\n",
    "        return(parameters[\"XGB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_params(A, B, P, N):\n",
    "    mu = np.random.dirichlet(P)\n",
    "    N = [int(mu_i*N) for mu_i in mu]\n",
    "    [sample_hp_Ai(classifiers_name[i]) for i in range(len(classifiers_name)) for j in range(N[i])]\n",
    "    Phi = sample_hp_Ai(\"XGB\")\n",
    "    Psi = [parameters[key] for key in parameters if key is not \"XGB\"]\n",
    "    return Phi, N, Psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Phi, N, Psi = get_params(classifiers_name, \"RF\", P=(np.arange(1,len(classifiers_name)+1)*100)[::-1], N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN {'n_neighbors': 51}\n",
      "SVM {'C': [], 'kernel': [], 'degree': []}\n",
      "GP {'kernel': [], 'n_restarts_optimizer': []}\n",
      "DT {'splitter': [], 'max_depth': []}\n",
      "RF {'n_estimators': [], 'max_depth': []}\n",
      "XGB {'learning_rate': [1.8], 'n_estimators': [1142], 'max_depth': [76], 'min_child_weight': [4]}\n"
     ]
    }
   ],
   "source": [
    "for key in parameters:\n",
    "    print(key,parameters[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Blend:\n",
    "    def __init__(self, A = [\"KNN\", \"SVM\", \"GP\", \"DT\", \"RF\"], B = \"XGB\",D = [], L = 2, Phi = [], Psi = [], N=100 ):\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.D = D\n",
    "        self.L = L\n",
    "        self.Phi = Phi\n",
    "        self.Psi = Psi\n",
    "        self.N = N\n",
    "                    \n",
    "    def fit(self, A, B, D, L, Phi, N, Psi):\n",
    "        p = np.random.normal(loc=0.7, scale=0.1)\n",
    "        Dfw = []\n",
    "        M = []\n",
    "        F = []\n",
    "        G = []\n",
    "        for l in range(1,L+1):\n",
    "            D_dash = D.sample(frac=p)\n",
    "            orig_index = sorted(Df.index.tolist())\n",
    "            train_index = sorted(D_dash.index.tolist())\n",
    "            test_index = sorted(set(orig_index) - set(train_index))\n",
    "            D_dash_bar = Df.ix[test_index]\n",
    "            classifier_index = 0\n",
    "            for i in range(0,len(classifiers_name)):\n",
    "                temp = []\n",
    "                if(N[i]):\n",
    "                    for j in range(0,N[i]):\n",
    "                        temp_clf = None\n",
    "                        temp_clf = classifiers[i].set_params(**classifier_parameters[classifier_index])\n",
    "                        temp_clf = temp_clf.fit(X = D_dash[\"X\"].tolist(), y = D_dash[\"Y\"].tolist())\n",
    "                        print(\"Temp Result is: \",temp_clf.predict_proba([[4.6, 3.4, 1.4, 0.3]]))\n",
    "                        temp.append(deepcopy(temp_clf))\n",
    "                        classifier_index += 1\n",
    "                M.append(temp)\n",
    "#             for row in D_dash[\"X\"]:\n",
    "#                 for model in M[0]:\n",
    "#                     print(\"MOdel is:\",model)\n",
    "#                     F.append(row*model.predict_proba([row]))\n",
    "        return(M,D_dash,F)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def blending_ensemble(A, B, D, P, N, k, R):\n",
    "    L = 2\n",
    "    M = []\n",
    "    for r in range(1,R+1):\n",
    "        Phi_r, N_r, Psi_r = get_params(A, B, P, N=10)\n",
    "        eps_r = cross_val_score(Blend(), A, B, D, L, Phi, Psi, N, cv=k)\n",
    "        print(eps_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "b =Blend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M_temp, D_dash, F = b.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
