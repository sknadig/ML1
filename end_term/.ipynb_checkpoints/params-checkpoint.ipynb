{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import math\n",
    "from sklearn import datasets, base\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from copy import deepcopy\n",
    "import itertools\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(n_jobs = -1),\n",
    "    SVC(probability = True),\n",
    "#     GaussianProcessClassifier(n_jobs = -1),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier()]\n",
    "\n",
    "# classifiers_name = [\"KNN\", \"SVM\", \"GP\", \"DT\", \"RF\"]\n",
    "classifiers_name = [\"KNN\", \"SVM\", \"DT\", \"RF\"]\n",
    "beta = \"XGB\"\n",
    "\n",
    "parameters = {\"KNN\":{\"n_neighbors\":[]},\n",
    "              \"SVM\":{\"C\":[],\"kernel\":[],\"degree\":[]},\n",
    "              \"GP\":{\"kernel\":[],\"n_restarts_optimizer\":[]},\n",
    "              \"DT\":{\"splitter\":[], \"max_depth\":[]},\n",
    "              \"RF\":{\"n_estimators\":[], \"max_depth\":[] },\n",
    "              \"XGB\":{\"learning_rate\":[], \"n_estimators\":[], \"max_depth\":[],\"min_child_weight\":[]}\n",
    "            }\n",
    "classifier_parameters = []\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "Df = pd.DataFrame()\n",
    "Df[\"X\"] = X.tolist()\n",
    "Df[\"Y\"] = Y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sample_hp_Ai(Ai):\n",
    "    global classifier_parameters\n",
    "    if(Ai is \"KNN\"):\n",
    "        parameters[\"KNN\"][\"n_neighbors\"] = math.ceil(np.random.uniform(100))\n",
    "        classifier_parameters.append(parameters[\"KNN\"].copy())\n",
    "        return(parameters[\"KNN\"])\n",
    "    elif(Ai is \"SVM\"):\n",
    "        parameters[\"SVM\"][\"C\"] = float(\"{0:.2f}\".format(abs(np.random.normal(loc=1.0, scale=1.0))))\n",
    "        parameters[\"SVM\"][\"kernel\"] = str(np.random.choice([\"linear\", \"rbf\"]))\n",
    "        parameters[\"SVM\"][\"degree\"] = np.random.randint(1,4)\n",
    "        classifier_parameters.append(parameters[\"SVM\"].copy())\n",
    "        return(parameters[\"SVM\"])\n",
    "    elif(Ai is \"GP\"):\n",
    "        parameters[\"GP\"][\"kernel\"] = str(np.random.choice([\"linear\", \"rbf\"]))\n",
    "        parameters[\"GP\"][\"n_restarts_optimizer\"] = np.random.randint(1,10)\n",
    "        classifier_parameters.append(parameters[\"GP\"].copy())\n",
    "        return(parameters[\"GP\"])\n",
    "    elif(Ai is \"DT\"):\n",
    "        parameters[\"DT\"][\"splitter\"] = np.random.choice([\"best\", \"random\"])\n",
    "        parameters[\"DT\"][\"max_depth\"] = np.random.randint(1,100)\n",
    "        classifier_parameters.append(parameters[\"DT\"].copy())\n",
    "        return(parameters[\"DT\"])\n",
    "    elif(Ai is \"RF\"):\n",
    "        parameters[\"RF\"][\"n_estimators\"] = np.random.randint(1,20)\n",
    "        parameters[\"RF\"][\"max_depth\"] = np.random.randint(1,100)\n",
    "        classifier_parameters.append(parameters[\"RF\"].copy())\n",
    "        return(parameters[\"RF\"])\n",
    "    elif(Ai is \"XGB\"):\n",
    "        parameters[\"XGB\"][\"learning_rate\"].append(float(\"{0:.2f}\".format(abs(np.random.normal(loc=1.0, scale=1.0)))))\n",
    "        parameters[\"XGB\"][\"n_estimators\"].append(np.random.randint(800,2000))\n",
    "        parameters[\"XGB\"][\"max_depth\"].append(np.random.randint(5,200))\n",
    "        parameters[\"XGB\"][\"min_child_weight\"].append(np.random.randint(1,10))\n",
    "        classifier_parameters.append(parameters[\"XGB\"].copy())\n",
    "        return(parameters[\"XGB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_params(A, B, P, N):\n",
    "    mu = np.random.dirichlet(P)\n",
    "    N = [int(mu_i*N) for mu_i in mu]\n",
    "    [sample_hp_Ai(classifiers_name[i]) for i in range(len(classifiers_name)) for j in range(N[i])]\n",
    "    Phi = sample_hp_Ai(\"XGB\")\n",
    "    Psi = [parameters[key] for key in parameters if key is not \"XGB\"]\n",
    "    return Phi, N, Psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Phi, N, Psi = get_params(classifiers_name, \"RF\", P=(np.arange(1,len(classifiers_name)+1)*100)[::-1], N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Blend:\n",
    "    def __init__(self, A = [\"KNN\", \"SVM\", \"GP\", \"DT\", \"RF\"], B = \"XGB\",D = [], L = 2, Phi = [], Psi = [], N=100 ):\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.D = D\n",
    "        self.L = L\n",
    "        self.Phi = Phi\n",
    "        self.Psi = Psi\n",
    "        self.N = N\n",
    "                    \n",
    "    def fit(self, A, B, D, L, Phi, N, Psi):\n",
    "#         p = np.random.normal(loc=0.7, scale=0.1)\n",
    "        p=0.7\n",
    "        D_fw = pd.DataFrame()\n",
    "        M = []\n",
    "        F = []\n",
    "        G = []\n",
    "        for l in range(1,L+1):\n",
    "            D_dash = D.sample(frac=p)\n",
    "            orig_index = sorted(Df.index.tolist())\n",
    "            train_index = sorted(D_dash.index.tolist())\n",
    "            test_index = sorted(set(orig_index) - set(train_index))\n",
    "            D_dash_bar = Df.ix[test_index]\n",
    "            classifier_index = 0\n",
    "            for i in range(0,len(classifiers_name)):\n",
    "                temp = []\n",
    "                if(N[i]):\n",
    "                    for j in range(0,N[i]):\n",
    "                        temp_clf = None\n",
    "                        temp_clf = classifiers[i].set_params(**classifier_parameters[classifier_index])\n",
    "                        temp_clf = temp_clf.fit(X = D_dash[\"X\"].tolist(), y = D_dash[\"Y\"].tolist())\n",
    "                        temp.append(deepcopy(temp_clf))\n",
    "                        classifier_index += 1\n",
    "                M.append(temp)\n",
    "            for row in D_dash_bar[\"X\"]:\n",
    "                F_temp = []\n",
    "                G_temp = []\n",
    "                for models in M:\n",
    "                    for model in models:\n",
    "                        M_bc = model.predict_proba([row])\n",
    "                        F_temp += [xa*ele for xa in row for ele in M_bc[0]]\n",
    "                        G_temp += [ele for ele in M_bc[0]]\n",
    "                F.append(F_temp)\n",
    "                G.append(G_temp)\n",
    "            d_assign = [list(itertools.chain.from_iterable(ele)) for ele in \\\n",
    "                        list(zip(D_dash_bar[\"X\"].tolist().copy(),F.copy(),G.copy()))]\n",
    "            D_fw[\"X\"] = d_assign\n",
    "            D_fw[\"Y\"] = D_dash_bar[\"Y\"].tolist().copy()\n",
    "            D_fw = D_fw.reset_index()\n",
    "            \n",
    "            Beta = xgb.XGBClassifier()\n",
    "            Beta.set_params(**classifier_parameters[-1])\n",
    "#             Beta = Beta.fit(X=D_fw[\"X\"], y=D_fw[\"Y\"])\n",
    "        return(M,D_dash,F,G, D_fw, Beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def blending_ensemble(A, B, D, P, N, k, R):\n",
    "    L = 2\n",
    "    M = []\n",
    "    for r in range(1,R+1):\n",
    "        Phi_r, N_r, Psi_r = get_params(A, B, P, N=10)\n",
    "        eps_r = cross_val_score(Blend(), A, B, D, L, Phi, Psi, N, cv=k)\n",
    "        print(eps_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b =Blend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6      0\n",
      "11     0\n",
      "13     0\n",
      "15     0\n",
      "16     0\n",
      "23     0\n",
      "25     0\n",
      "29     0\n",
      "31     0\n",
      "33     0\n",
      "38     0\n",
      "39     0\n",
      "43     0\n",
      "45     0\n",
      "46     0\n",
      "48     0\n",
      "50     1\n",
      "53     1\n",
      "57     1\n",
      "58     1\n",
      "60     1\n",
      "61     1\n",
      "64     1\n",
      "66     1\n",
      "69     1\n",
      "72     1\n",
      "74     1\n",
      "77     1\n",
      "81     1\n",
      "86     1\n",
      "89     1\n",
      "90     1\n",
      "91     1\n",
      "94     1\n",
      "95     1\n",
      "96     1\n",
      "97     1\n",
      "99     1\n",
      "101    2\n",
      "104    2\n",
      "105    2\n",
      "116    2\n",
      "117    2\n",
      "118    2\n",
      "130    2\n",
      "Name: Y, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "M_temp, D_dash, F, G, D_fw, Beta = b.fit(A=classifiers_name, B=\"XGB\", D=Df, L=1, Phi=Phi, N=N, Psi=Psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     NaN\n",
       "1     NaN\n",
       "2     NaN\n",
       "3     NaN\n",
       "4     NaN\n",
       "5     NaN\n",
       "6     0.0\n",
       "7     NaN\n",
       "8     NaN\n",
       "9     NaN\n",
       "10    NaN\n",
       "11    0.0\n",
       "12    NaN\n",
       "13    0.0\n",
       "14    NaN\n",
       "15    0.0\n",
       "16    0.0\n",
       "17    NaN\n",
       "18    NaN\n",
       "19    NaN\n",
       "20    NaN\n",
       "21    NaN\n",
       "22    NaN\n",
       "23    0.0\n",
       "24    NaN\n",
       "25    0.0\n",
       "26    NaN\n",
       "27    NaN\n",
       "28    NaN\n",
       "29    0.0\n",
       "30    NaN\n",
       "31    0.0\n",
       "32    NaN\n",
       "33    0.0\n",
       "34    NaN\n",
       "35    NaN\n",
       "36    NaN\n",
       "37    NaN\n",
       "38    0.0\n",
       "39    0.0\n",
       "40    NaN\n",
       "41    NaN\n",
       "42    NaN\n",
       "43    0.0\n",
       "44    NaN\n",
       "Name: Y, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_fw[\"Y\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
