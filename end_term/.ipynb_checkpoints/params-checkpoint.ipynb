{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import math\n",
    "from sklearn import datasets, base\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from copy import deepcopy\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(n_jobs = -1),\n",
    "    SVC(probability = True),\n",
    "#     GaussianProcessClassifier(n_jobs = -1),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier()]\n",
    "\n",
    "# classifiers_name = [\"KNN\", \"SVM\", \"GP\", \"DT\", \"RF\"]\n",
    "classifiers_name = [\"KNN\", \"SVM\", \"DT\", \"RF\"]\n",
    "beta = \"XGB\"\n",
    "\n",
    "parameters = {\"KNN\":{\"n_neighbors\":[]},\n",
    "              \"SVM\":{\"C\":[],\"kernel\":[],\"degree\":[]},\n",
    "              \"GP\":{\"kernel\":[],\"n_restarts_optimizer\":[]},\n",
    "              \"DT\":{\"splitter\":[], \"max_depth\":[]},\n",
    "              \"RF\":{\"n_estimators\":[], \"max_depth\":[] },\n",
    "              \"XGB\":{\"learning_rate\":[], \"n_estimators\":[], \"max_depth\":[],\"min_child_weight\":[]}\n",
    "            }\n",
    "classifier_parameters = []\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "Df = pd.DataFrame()\n",
    "Df[\"X\"] = X.tolist()\n",
    "Df[\"Y\"] = Y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sample_hp_Ai(Ai):\n",
    "    global classifier_parameters\n",
    "    if(Ai is \"KNN\"):\n",
    "        parameters[\"KNN\"][\"n_neighbors\"] = math.ceil(np.random.uniform(100))\n",
    "        classifier_parameters.append(parameters[\"KNN\"].copy())\n",
    "        return(parameters[\"KNN\"])\n",
    "    elif(Ai is \"SVM\"):\n",
    "        parameters[\"SVM\"][\"C\"] = float(\"{0:.2f}\".format(abs(np.random.normal(loc=1.0, scale=1.0))))\n",
    "        parameters[\"SVM\"][\"kernel\"] = str(np.random.choice([\"linear\", \"rbf\"]))\n",
    "        parameters[\"SVM\"][\"degree\"] = np.random.randint(1,4)\n",
    "        classifier_parameters.append(parameters[\"SVM\"].copy())\n",
    "        return(parameters[\"SVM\"])\n",
    "    elif(Ai is \"GP\"):\n",
    "        parameters[\"GP\"][\"kernel\"] = str(np.random.choice([\"linear\", \"rbf\"]))\n",
    "        parameters[\"GP\"][\"n_restarts_optimizer\"] = np.random.randint(1,10)\n",
    "        classifier_parameters.append(parameters[\"GP\"].copy())\n",
    "        return(parameters[\"GP\"])\n",
    "    elif(Ai is \"DT\"):\n",
    "        parameters[\"DT\"][\"splitter\"] = np.random.choice([\"best\", \"random\"])\n",
    "        parameters[\"DT\"][\"max_depth\"] = np.random.randint(1,100)\n",
    "        classifier_parameters.append(parameters[\"DT\"].copy())\n",
    "        return(parameters[\"DT\"])\n",
    "    elif(Ai is \"RF\"):\n",
    "        parameters[\"RF\"][\"n_estimators\"] = np.random.randint(1,20)\n",
    "        parameters[\"RF\"][\"max_depth\"] = np.random.randint(1,100)\n",
    "        classifier_parameters.append(parameters[\"RF\"].copy())\n",
    "        return(parameters[\"RF\"])\n",
    "    elif(Ai is \"XGB\"):\n",
    "        parameters[\"XGB\"][\"learning_rate\"].append(float(\"{0:.2f}\".format(abs(np.random.normal(loc=1.0, scale=1.0)))))\n",
    "        parameters[\"XGB\"][\"n_estimators\"].append(np.random.randint(800,2000))\n",
    "        parameters[\"XGB\"][\"max_depth\"].append(np.random.randint(5,200))\n",
    "        parameters[\"XGB\"][\"min_child_weight\"].append(np.random.randint(1,10))\n",
    "        classifier_parameters.append(parameters[\"XGB\"].copy())\n",
    "        return(parameters[\"XGB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_params(A, B, P, N):\n",
    "    mu = np.random.dirichlet(P)\n",
    "    N = [int(mu_i*N) for mu_i in mu]\n",
    "    [sample_hp_Ai(classifiers_name[i]) for i in range(len(classifiers_name)) for j in range(N[i])]\n",
    "    Phi = sample_hp_Ai(\"XGB\")\n",
    "    Psi = [parameters[key] for key in parameters if key is not \"XGB\"]\n",
    "    return Phi, N, Psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Phi, N, Psi = get_params(classifiers_name, \"RF\", P=(np.arange(1,len(classifiers_name)+1)*100)[::-1], N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4, 2, 1, 1],\n",
       " [{'n_neighbors': 27},\n",
       "  {'n_neighbors': 84},\n",
       "  {'n_neighbors': 14},\n",
       "  {'n_neighbors': 58},\n",
       "  {'C': 1.06, 'degree': 1, 'kernel': 'rbf'},\n",
       "  {'C': 0.17, 'degree': 1, 'kernel': 'linear'},\n",
       "  {'max_depth': 14, 'splitter': 'random'},\n",
       "  {'max_depth': 79, 'n_estimators': 15},\n",
       "  {'learning_rate': [2.19],\n",
       "   'max_depth': [162],\n",
       "   'min_child_weight': [1],\n",
       "   'n_estimators': [1171]}])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N,classifier_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Blend:\n",
    "    def __init__(self, A = [\"KNN\", \"SVM\", \"GP\", \"DT\", \"RF\"], B = \"XGB\",D = [], L = 2, Phi = [], Psi = [], N=100 ):\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.D = D\n",
    "        self.L = L\n",
    "        self.Phi = Phi\n",
    "        self.Psi = Psi\n",
    "        self.N = N\n",
    "                    \n",
    "    def fit(self, A, B, D, L, Phi, N, Psi):\n",
    "#         p = np.random.normal(loc=0.7, scale=0.1)\n",
    "        p=0.7\n",
    "        Dfw = []\n",
    "        M = []\n",
    "        F = []\n",
    "        G = []\n",
    "        for l in range(1,L+1):\n",
    "            D_dash = D.sample(frac=p)\n",
    "            orig_index = sorted(Df.index.tolist())\n",
    "            train_index = sorted(D_dash.index.tolist())\n",
    "            test_index = sorted(set(orig_index) - set(train_index))\n",
    "            D_dash_bar = Df.ix[test_index]\n",
    "            classifier_index = 0\n",
    "            for i in range(0,len(classifiers_name)):\n",
    "                temp = []\n",
    "                if(N[i]):\n",
    "                    for j in range(0,N[i]):\n",
    "                        print(\"Training: \", classifiers_name[i])\n",
    "                        temp_clf = None\n",
    "                        temp_clf = classifiers[i].set_params(**classifier_parameters[classifier_index])\n",
    "#                         print(\"Fitting: {0}\\n\".format(temp_clf))\n",
    "                        temp_clf = temp_clf.fit(X = D_dash[\"X\"].tolist(), y = D_dash[\"Y\"].tolist())\n",
    "#                         print(\"Temp Result is: \",temp_clf.predict_proba([[4.6, 3.4, 1.4, 0.3]]))\n",
    "                        temp.append(deepcopy(temp_clf))\n",
    "                        classifier_index += 1\n",
    "                M.append(temp)\n",
    "#             for row in D_dash[\"X\"]:\n",
    "#                 for model in M[0]:\n",
    "#                     print(\"MOdel is:\",model)\n",
    "#                     F.append(row*model.predict_proba([row]))\n",
    "        return(M,D_dash,F)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def blending_ensemble(A, B, D, P, N, k, R):\n",
    "    L = 2\n",
    "    M = []\n",
    "    for r in range(1,R+1):\n",
    "        Phi_r, N_r, Psi_r = get_params(A, B, P, N=10)\n",
    "        eps_r = cross_val_score(Blend(), A, B, D, L, Phi, Psi, N, cv=k)\n",
    "        print(eps_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n_neighbors': 27},\n",
       " {'n_neighbors': 84},\n",
       " {'n_neighbors': 14},\n",
       " {'n_neighbors': 58},\n",
       " {'C': 1.06, 'degree': 1, 'kernel': 'rbf'},\n",
       " {'C': 0.17, 'degree': 1, 'kernel': 'linear'},\n",
       " {'max_depth': 14, 'splitter': 'random'},\n",
       " {'max_depth': 79, 'n_estimators': 15},\n",
       " {'learning_rate': [2.19],\n",
       "  'max_depth': [162],\n",
       "  'min_child_weight': [1],\n",
       "  'n_estimators': [1171]}]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "b =Blend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  KNN\n",
      "Training:  KNN\n",
      "Training:  KNN\n",
      "Training:  KNN\n",
      "Training:  SVM\n",
      "Training:  SVM\n",
      "Training:  DT\n",
      "Training:  RF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "M_temp, D_dash, F = b.fit(A=classifiers_name, B=\"XGB\", D=Df, L=1, Phi=Phi, N=N, Psi=Psi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
